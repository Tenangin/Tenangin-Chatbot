{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "020ac373",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.environ.get(\"GOOGLE_API_KEY\"):\n",
    "  os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter API key for Google Gemini: \")\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "llm = init_chat_model(\"gemini-2.0-flash\", model_provider=\"google_genai\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ada2ae9",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Kamu adalah seorang konselor virtual yang ramah, empatik, dan sangat peduli terhadap kesehatan mental. \n",
    "Berikan jawaban dengan bahasa yang hangat, tidak menghakimi, dan mendukung.\n",
    "\n",
    "Informasi tambahan: \n",
    "{context}\n",
    "\n",
    "Pertanyaan dari pengguna:\n",
    "{question}\n",
    "\n",
    "Berikan jawaban yang membantu, berempati, dan menguatkan.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ea862b",
   "metadata": {},
   "source": [
    "Kamu adalah konselor profesional yang penuh empati. Berdasarkan konteks berikut, berikan respons singkat, manusiawi, dan berfokus pada inti masalah pengguna.\n",
    "\n",
    "Gunakan bahasa yang sederhana, suportif, dan tidak menggurui.\n",
    "\n",
    "Setelah memberikan sedikit pemahaman atau dukungan, akhiri dengan kalimat yang membuka ruang untuk pengguna berbagi lebih banyak atau memperdalam pembicaraan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50f6c283",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "\"\"\"\n",
    "Kamu adalah konselor profesional yang penuh empati. Berdasarkan konteks berikut, berikan respons singkat, manusiawi, dan berfokus pada inti masalah pengguna.\n",
    "Gunakan bahasa yang sederhana, suportif, dan tidak menggurui.\n",
    "\n",
    "Informasi tambahan: \n",
    "{context}\n",
    "\n",
    "Pertanyaan dari pengguna:\n",
    "{question}\n",
    "\n",
    "Setelah memberikan sedikit pemahaman atau dukungan, akhiri dengan kalimat yang membuka ruang untuk pengguna berbagi lebih banyak atau memperdalam pembicaraan.\n",
    "\"\"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f923b7f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODING\\PYTHON\\MACHINE_LEARNING\\Tenangin\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "d:\\CODING\\PYTHON\\MACHINE_LEARNING\\Tenangin\\.venv\\Lib\\site-packages\\transformers\\utils\\hub.py:105: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings.base import Embeddings\n",
    "import torch\n",
    "from langchain.schema import Document\n",
    "\n",
    "# Load SBERT model dan pastikan menggunakan GPU jika tersedia\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "sbert_model = model = SentenceTransformer('naufalihsan/indonesian-sbert-large')\n",
    "sbert_model = sbert_model.to(device)  # Pindahkan model ke GPU (jika ada)\n",
    "\n",
    "# Custom embeddings class for SBERT\n",
    "class SBERTEmbeddings(Embeddings):\n",
    "    def embed_documents(self, texts: list[str]) -> list[list[float]]:\n",
    "        # Menggunakan model SBERT untuk menghasilkan embeddings\n",
    "        embeddings = sbert_model.encode(texts, convert_to_tensor=True, show_progress_bar=True)\n",
    "        embeddings = embeddings.to(device)  # Pindahkan embeddings ke GPU (jika ada)\n",
    "        return embeddings.cpu().numpy().tolist()  # Pindahkan kembali ke CPU untuk konversi\n",
    "\n",
    "    def embed_query(self, query: str) -> list[float]:\n",
    "        # Menghasilkan embedding untuk query\n",
    "        embedding = sbert_model.encode(query, convert_to_tensor=True)\n",
    "        embedding = embedding.to(device)  # Pindahkan embedding ke GPU (jika ada)\n",
    "        return embedding.cpu().numpy().tolist()  # Pindahkan kembali ke CPU untuk konversi\n",
    "\n",
    "# Inisialisasi embeddings SBERT dan FAISS vector store\n",
    "sbert_embeddings = SBERTEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ceeb8329",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import START, StateGraph\n",
    "from typing_extensions import List, TypedDict\n",
    "from langchain_core.documents import Document\n",
    "from langchain.vectorstores import FAISS\n",
    "vector_store = FAISS.load_local(\"tudocs_faiss\",sbert_embeddings,allow_dangerous_deserialization=True)\n",
    "\n",
    "\n",
    "# Define state for application\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context: List[Document]\n",
    "    answer: str\n",
    "\n",
    "\n",
    "# Define application steps\n",
    "def retrieve(state: State):\n",
    "    retrieved_docs = vector_store.similarity_search(state[\"question\"])\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "\n",
    "def generate(state: State):\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"answer\": response.content}\n",
    "\n",
    "\n",
    "# Compile application and test\n",
    "graph_builder = StateGraph(State).add_sequence([retrieve, generate])\n",
    "graph_builder.add_edge(START, \"retrieve\")\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a54f2603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anda    : aku ngerasa sedih banget hari ini huhu\n",
      "Gemini  : Aku turut merasakan kesedihanmu. Sedih itu emosi yang wajar kok, dan nggak apa-apa untuk merasakannya. Kadang, hidup memang terasa berat ya?\n",
      "\n",
      "Apakah ada sesuatu spesifik yang membuatmu merasa sedih hari ini? Ceritakan saja jika kamu merasa nyaman.\n",
      "Context : lainnya (Nierenberg, 2001). Gangguan mood adalah disfungsi neurobiologi yang menyebabkan perubahan respons emosional. Gangguan mood mengganggu kehidupan seseorang. Orang-orang dipenuhi dengan kesedihan, kegembiraan atau kegembiraan yang berkepanjangan dan intens, disertai dengan keraguan diri, rasa bersalah dan kemarahan, yang mengubah aktivitas hidup mereka, terutama aktivitas yang berkaitan dengan harga diri, pekerjaan, dan hubungan (Videbeck, 2011), dan ketika kondisi ini berlangsung lama dan terus menerus, orang bisa mengalami keputusasaan dan bunuh diri. Kematian akibat bunuh diri dapat dicegah dan dapat mengurangi kejadian bunuh diri. Memahami, mendeteksi, dan mengobati gangguan mood dapat digunakan sebagai dasar \fpencegahan bunuh diri. Bab ini membahas gangguan mood dan bunuh diri.\n"
     ]
    }
   ],
   "source": [
    "response = graph.invoke({\"question\": \"aku ngerasa sedih banget hari ini huhu\"})\n",
    "print(f\"Anda    : {response['question']}\")\n",
    "print(f\"Gemini  : {response['answer']}\")\n",
    "print(f\"Context : {response['context'][0].page_content}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
