{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "020ac373",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.environ.get(\"GOOGLE_API_KEY\"):\n",
    "  os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter API key for Google Gemini: \")\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "llm = init_chat_model(\"gemini-2.0-flash\", model_provider=\"google_genai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50f6c283",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODING\\PYTHON\\MACHINE_LEARNING\\Tenangin\\.venv\\Lib\\site-packages\\langsmith\\client.py:272: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, metadata={'lc_hub_owner': 'rlm', 'lc_hub_repo': 'rag-prompt', 'lc_hub_commit_hash': '50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6e'}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"), additional_kwargs={})])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import hub\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f923b7f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODING\\PYTHON\\MACHINE_LEARNING\\Tenangin\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "d:\\CODING\\PYTHON\\MACHINE_LEARNING\\Tenangin\\.venv\\Lib\\site-packages\\transformers\\utils\\hub.py:105: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings.base import Embeddings\n",
    "import torch\n",
    "from langchain.schema import Document\n",
    "\n",
    "# Load SBERT model dan pastikan menggunakan GPU jika tersedia\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "sbert_model = model = SentenceTransformer('naufalihsan/indonesian-sbert-large')\n",
    "sbert_model = sbert_model.to(device)  # Pindahkan model ke GPU (jika ada)\n",
    "\n",
    "# Custom embeddings class for SBERT\n",
    "class SBERTEmbeddings(Embeddings):\n",
    "    def embed_documents(self, texts: list[str]) -> list[list[float]]:\n",
    "        # Menggunakan model SBERT untuk menghasilkan embeddings\n",
    "        embeddings = sbert_model.encode(texts, convert_to_tensor=True, show_progress_bar=True)\n",
    "        embeddings = embeddings.to(device)  # Pindahkan embeddings ke GPU (jika ada)\n",
    "        return embeddings.cpu().numpy().tolist()  # Pindahkan kembali ke CPU untuk konversi\n",
    "\n",
    "    def embed_query(self, query: str) -> list[float]:\n",
    "        # Menghasilkan embedding untuk query\n",
    "        embedding = sbert_model.encode(query, convert_to_tensor=True)\n",
    "        embedding = embedding.to(device)  # Pindahkan embedding ke GPU (jika ada)\n",
    "        return embedding.cpu().numpy().tolist()  # Pindahkan kembali ke CPU untuk konversi\n",
    "\n",
    "# Inisialisasi embeddings SBERT dan FAISS vector store\n",
    "sbert_embeddings = SBERTEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ceeb8329",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import START, StateGraph\n",
    "from typing_extensions import List, TypedDict\n",
    "from langchain_core.documents import Document\n",
    "from langchain.vectorstores import FAISS\n",
    "vector_store = FAISS.load_local(\"tudocs_faiss\",sbert_embeddings,allow_dangerous_deserialization=True)\n",
    "\n",
    "\n",
    "# Define state for application\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context: List[Document]\n",
    "    answer: str\n",
    "\n",
    "\n",
    "# Define application steps\n",
    "def retrieve(state: State):\n",
    "    retrieved_docs = vector_store.similarity_search(state[\"question\"])\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "\n",
    "def generate(state: State):\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"answer\": response.content}\n",
    "\n",
    "\n",
    "# Compile application and test\n",
    "graph_builder = StateGraph(State).add_sequence([retrieve, generate])\n",
    "graph_builder.add_edge(START, \"retrieve\")\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a54f2603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anda    : kenapa ya, saya merasa tidak berguna. saya kurang dihargai orang lain karena hal itu.\n",
      "Gemini  : Merasa tidak berguna dan kurang dihargai bisa disebabkan oleh beberapa faktor, seperti gangguan kepribadian menghindar yang membuat individu takut dihakimi dan memiliki harga diri rendah. Kurangnya motivasi juga bisa menjadi penyebab, yang mana setiap orang pasti mengalaminya. Interaksi yang penuh kasih dan tidak menghakimi dari orang tua sangat penting untuk mengatasi motivasi yang rendah.\n",
      "Context : orang lain mengambil tanggung jawab atas sebagian hidupnya. Seseorang merasa kurang percaya diri atau tidak mampu melakukan hal-hal normal sendirian sehingga menempatkan kebutuhan diri sendiri di atas kebutuhan orang lain, dan merasa putus asa atau takut sendirian. 2) Gangguan kepribadian menghindar Jika memiliki gangguan kepribadian menghindar, mungkin takut dihakimi secara negatif. Ini dapat menyebabkan induvidu merasa tidak nyaman dalam situasi sosial. Seserang akan merasa peka terhadap kritik, sangat khawatir, dan memiliki harga diri yang rendah. Sehingga, mungkin menginginkan kasih sayang, tetapi khawatir akan ditolak. 3) Gangguan kepribadian obsesif-kompulsif Jika memiliki kondisi ini, mungkin akan merasa cemas dengan masalah yang tampak tidak teratur atau 'berantakan'. Segala sesuatu yang dilakukan harus tepat, dan tidak ada yang bisa dibiarkan begitu saja. seseorang mungkin terlalu berhati-hati tentang berbagai hal dan disibukkan dengan detail. Orang lain mungkin menganggapnya\n"
     ]
    }
   ],
   "source": [
    "response = graph.invoke({\"question\": \"kenapa ya, saya merasa tidak berguna. saya kurang dihargai orang lain karena hal itu.\"})\n",
    "print(f\"Anda    : {response['question']}\")\n",
    "print(f\"Gemini  : {response['answer']}\")\n",
    "print(f\"Context : {response['context'][0].page_content}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
